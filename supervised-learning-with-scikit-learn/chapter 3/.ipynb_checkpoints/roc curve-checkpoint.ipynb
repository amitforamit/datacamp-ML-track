{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6",
      "name": "python36",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat_minor": 2,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In Machine Learning, performance measurement is an essential task. So when it comes to a classification problem, we can count on an AUC - ROC Curve. When we need to check or visualize the performance of the multi - class classification problem, we use AUC (Area Under The Curve) ROC (Receiver Operating Characteristics) curve. It is one of the most important evaluation metrics for checking any classification modelâ€™s performance. It is also written as AUROC (Area Under the Receiver Operating Characteristics)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h3>What is AUC - ROC Curve?</h3>\nAUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The ROC curve is plotted with TPR against the FPR where TPR is on y-axis and FPR is on the x-axis.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<img src='AUCROC.jpg'>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h3>How to speculate the performance of the model?</h3>\nAn excellent model has AUC near to the 1 which means it has good measure of separability. A poor model has AUC near to the 0 which means it has worst measure of separability. In fact it means it is reciprocating the result. It is predicting 0s as 1s and 1s as 0s. And when AUC is 0.5, it means model has no class separation capacity whatsoever.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}